{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from scrapy import Selector\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import random\n",
    "from lxml import etree\n",
    "times = time.strftime('%a %b %d %Y %H:%M:%S') + ' GMT+0800 (中国标准时间)'\n",
    "import string\n",
    "import pickle\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "string.punctuation=string.punctuation+'；'\n",
    "class paper:\n",
    "    def __init__(self, name, authors,orgns, summary = [], funds = [],keywords = []):\n",
    "        self.name = name\n",
    "        self.authors = authors\n",
    "        self.orgns = orgns\n",
    "        self.summary = summary\n",
    "        self.funds = funds\n",
    "        self.keywords = keywords\n",
    "        \n",
    "    def save():\n",
    "        pass\n",
    "\n",
    "def ch():\n",
    "    iframe = browser.find_element_by_id('iframeResult')\n",
    "    if(iframe):\n",
    "        browser.switch_to.frame(iframe)\n",
    "    browser.find_element_by_css_selector('a.Ch').click()\n",
    "    browser.switch_to.parent_frame()\n",
    "    \n",
    "def init(keyword):\n",
    "    browser.get('https://kns.cnki.net/')\n",
    "    time.sleep(random.uniform(2,4))\n",
    "    screachtext = browser.find_element_by_id('txt_SearchText')\n",
    "    screachtext.send_keys(keyword)\n",
    "    btn = browser.find_element_by_class_name('search-btn')\n",
    "    btn.click()\n",
    "\n",
    "def changeKeyword(keyword):\n",
    "    screachtext = browser.find_element_by_id('txt_1_value1')\n",
    "    screachtext.clear()\n",
    "    screachtext.send_keys(keyword)\n",
    "    btn = browser.find_element_by_id('btnSearch')\n",
    "    btn.click()\n",
    "    \n",
    "def downdata(papers,i):\n",
    "    iframe = browser.find_element_by_css_selector('iframe#iframeResult')\n",
    "    if(iframe):\n",
    "        browser.switch_to.frame('iframeResult')\n",
    "    a=browser.find_elements_by_css_selector('a.fz14')\n",
    "    a[i].click()\n",
    "    #句柄控制\n",
    "    n = browser.window_handles\n",
    "    print('当前句柄: ', n)\n",
    "    browser.switch_to.window(n[-1])\n",
    "    #从浏览器中提取信息\n",
    "    #等待2秒\n",
    "    time.sleep(random.uniform(2,4))\n",
    "    divpaper_name=browser.find_elements_by_css_selector('h2.title')[0]\n",
    "    divauthors=browser.find_elements_by_css_selector('div.author')[0].find_elements_by_css_selector('a')\n",
    "    divorgn=browser.find_elements_by_css_selector('div.orgn')[0].find_elements_by_css_selector('a')\n",
    "    divwxBaseinfo=browser.find_elements_by_css_selector('div.wxBaseinfo')[0].find_elements_by_css_selector('p')\n",
    "    divChDivSummary=divwxBaseinfo[0].find_element_by_id('ChDivSummary')\n",
    "    divcatalog_FUNDs=divwxBaseinfo[1].find_elements_by_css_selector('a')\n",
    "    divcatalog_KEYWORDs=divwxBaseinfo[2].find_elements_by_css_selector('a')\n",
    "\n",
    "    #把数据读到内存\n",
    "    paper_name=divpaper_name.text\n",
    "    authors=[]\n",
    "    orgns = []\n",
    "    funds = []\n",
    "    keywords = []\n",
    "    summary = divChDivSummary.text\n",
    "    for y in range(len(divauthors)):\n",
    "        authors.append(divauthors[y].text)\n",
    "    for y in range(len(divorgn)):\n",
    "        orgns.append(divorgn[y].text)\n",
    "    for y in range(len(divcatalog_FUNDs)):\n",
    "        funds.append(divcatalog_FUNDs[y].text)\n",
    "    for y in range(len(divcatalog_KEYWORDs)):\n",
    "        keywords.append(divcatalog_KEYWORDs[y].text)\n",
    "    a=paper(paper_name,authors,orgns,summary,funds,keywords)\n",
    "    papers.append(a)\n",
    "    switch()\n",
    "\n",
    "def switch():\n",
    "    browser.close();\n",
    "    n = browser.window_handles\n",
    "    print('当前句柄: ', n)\n",
    "    browser.switch_to.window(n[-1])\n",
    "    \n",
    "def getpage():\n",
    "    n = browser.window_handles\n",
    "    print('当前句柄: ', n)\n",
    "    browser.switch_to.window(n[-1])\n",
    "    \n",
    "def save(filepath,papers):\n",
    "    with open(filepath,\"wb\")as f:\n",
    "        pickle.dump(papers, f)\n",
    "\n",
    "        \n",
    "papers=[]\n",
    "if __name__ == '__main__':\n",
    "    browser = webdriver.Chrome('F:\\\\Chrome\\\\ChromeCore\\\\chromedriver.exe')\n",
    "    count = 0\n",
    "    init('知识图谱')\n",
    "    time.sleep(random.uniform(2,4))\n",
    "    ch()\n",
    "    while(count<100):\n",
    "        for i in range(2):\n",
    "            try:\n",
    "                downdata(papers,i)\n",
    "                count+=1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                switch()\n",
    "                continue\n",
    "        ActionChains(browser).key_down(Keys.ARROW_RIGHT).perform()\n",
    "        time.sleep(random.uniform(2,4))\n",
    "    save('data.txt',paper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
